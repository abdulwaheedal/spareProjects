import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, roc_curve, auc
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Load the trained model
model = load_model('malware_cnn_model.keras')

# Create the test generator (adjust the directory path as needed)
test_dir = 'Dataset/test'
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(128, 128),  # Match the training target_size from cnn_model.py
    batch_size=16,           # Match the training batch_size from cnn_model.py
    color_mode='grayscale',
    class_mode='categorical',
    shuffle=False
)

# Make predictions on the test set
# Calculate the exact number of steps to cover all test samples
steps = (test_generator.samples + test_generator.batch_size - 1) // test_generator.batch_size
y_pred_prob = model.predict(test_generator, steps=steps)
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = test_generator.classes  # True labels from the generator

# Calculate accuracy and precision
acc = accuracy_score(y_true, y_pred)
prec = precision_score(y_true, y_pred, average='macro')  # Macro average for multi-class
print("Test Accuracy: {:.2f}".format(acc))
print("Test Precision (macro): {:.2f}".format(prec))

# For ROC-AUC, convert true labels to one-hot encoding
num_classes = len(test_generator.class_indices)
y_true_onehot = to_categorical(y_true, num_classes=num_classes)

# Calculate ROC-AUC for each class (one-vs-rest)
try:
    # Use 'ovr' (one-vs-rest) for multi-class ROC-AUC
    roc_auc = roc_auc_score(y_true_onehot, y_pred_prob, multi_class='ovr', average='macro')
    print("Test ROC AUC Score (macro): {:.2f}".format(roc_auc))
except Exception as e:
    print("Error computing ROC AUC Score:", e)

# Plot ROC curves for each class
fpr = dict()
tpr = dict()
roc_auc_dict = dict()

plt.figure(figsize=(10, 8))
for i in range(num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_pred_prob[:, i])
    roc_auc_dict[i] = auc(fpr[i], tpr[i])
    plt.plot(fpr[i], tpr[i], label=f'ROC curve for class {i} (area = {roc_auc_dict[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curves')
plt.legend(loc="lower right")
plt.show()